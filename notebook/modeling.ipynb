{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Predictive Modeling for Risk-Based Pricing\n",
    "\n",
    "This notebook builds and evaluates predictive models to support dynamic, risk-based insurance pricing. The workflow is modular and leverages utility functions from `src/modeling_utils.py` for clean, reusable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../src')\n",
    "from utils.task4_utils import (\n",
    "    prepare_data, train_linear_regression, train_random_forest, train_xgboost,\n",
    "    regression_metrics, classification_metrics, get_feature_importance, shap_summary_plot\n",
    ")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import sys\n",
    "sys.path.append('../src/utils')\n",
    "import importlib\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "from utils.task4_utils import (\n",
    "    prepare_data, train_linear_regression, train_random_forest, train_xgboost,\n",
    "    regression_metrics, classification_metrics, get_feature_importance, shap_summary_plot\n",
    ")\n",
    "\n",
    "# If you want to reload after editing task4_utils.py:\n",
    "import utils.task4_utils as t4u\n",
    "importlib.reload(t4u)\n",
    "from utils.task4_utils import filter_flat_numeric_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "- Loads data\n",
    "- Handles missing values and encodes categoricals\n",
    "- Performs feature engineering\n",
    "- Splits into train/test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\senta\\AppData\\Local\\Temp\\ipykernel_21672\\3359248328.py:1: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/MachineLearningRating_v3.txt', sep='|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth',\n",
      "       'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language',\n",
      "       'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province',\n",
      "       'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode',\n",
      "       'VehicleType', 'RegistrationYear', 'make', 'Model', 'Cylinders',\n",
      "       'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors',\n",
      "       'VehicleIntroDate', 'CustomValueEstimate', 'AlarmImmobiliser',\n",
      "       'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'WrittenOff',\n",
      "       'Rebuilt', 'Converted', 'CrossBorder', 'NumberOfVehiclesInFleet',\n",
      "       'SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm',\n",
      "       'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section',\n",
      "       'Product', 'StatutoryClass', 'StatutoryRiskType', 'TotalPremium',\n",
      "       'TotalClaims'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/MachineLearningRating_v3.txt', sep='|')\n",
    "# For claim severity model: only use rows where TotalClaims > 0\n",
    "df_claims = df[df['TotalClaims'] > 0].copy()\n",
    "# Prepare data for regression (claim severity)\n",
    "drop_cols = ['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', 'TotalPremium', 'CalculatedPremiumPerTerm']\n",
    "# Do NOT include 'TotalClaims' in drop_cols\n",
    "X_train, X_test, y_train, y_test = prepare_data(df_claims, target='TotalClaims', drop_cols=drop_cols, regression=True)\n",
    "print(df_claims.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building: Claim Severity (Regression)\n",
    "Train and evaluate Linear Regression, Random Forest, and XGBoost models. Compare RMSE and R2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\senta\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\senta\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: {'RMSE': np.float64(39834.462843018184), 'R2': np.float64(0.013345926347972825)}\n",
      "Linear Regression: {'RMSE': np.float64(37213.81225950447), 'R2': np.float64(0.13889659295005807)}\n",
      "Random Forest: {'RMSE': np.float64(37078.7649885877), 'R2': np.float64(0.1451350647989721)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\senta\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# XGBoost (filter and align test set columns)\n",
    "xgb_model = train_xgboost(X_train, y_train, regression=True)\n",
    "X_test_filtered = filter_flat_numeric_columns(X_test)\n",
    "X_test_filtered = X_test_filtered[list(xgb_model.feature_names_in_)]\n",
    "xgb_pred = xgb_model.predict(X_test_filtered)\n",
    "xgb_metrics = regression_metrics(y_test, xgb_pred)\n",
    "print('XGBoost:', xgb_metrics)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = train_linear_regression(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_metrics = regression_metrics(y_test, lr_pred)\n",
    "print('Linear Regression:', lr_metrics)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = train_random_forest(X_train, y_train, regression=True)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_metrics = regression_metrics(y_test, rf_pred)\n",
    "print('Random Forest:', rf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation (SHAP)\n",
    "Interpret the best-performing regression model using SHAP to identify top features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|==================  | 2057/2230 [01:34<00:07]       "
     ]
    }
   ],
   "source": [
    "# Use the exact preprocessed training DataFrame for SHAP\n",
    "X_train_prepared = X_train\n",
    "shap_summary_plot(rf_model, X_train_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premium Optimization: Claim Probability Model (Classification)\n",
    "Train and evaluate models to predict the probability of a claim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HasClaim'] = df['TotalClaims'] > 0\n",
    "drop_cols_class = ['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', 'TotalPremium', 'CalculatedPremiumPerTerm', 'TotalClaims', 'HasClaim']\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = prepare_data(df, target='HasClaim', drop_cols=drop_cols_class, regression=False)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = train_random_forest(X_train_c, y_train_c, regression=False)\n",
    "rf_clf_pred = rf_clf.predict(X_test_c)\n",
    "rf_clf_metrics = classification_metrics(y_test_c, rf_clf_pred)\n",
    "print('Random Forest Classifier:', rf_clf_metrics)\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_clf = train_xgboost(X_train_c, y_train_c, regression=False)\n",
    "xgb_clf_pred = xgb_clf.predict(X_test_c)\n",
    "xgb_clf_metrics = classification_metrics(y_test_c, xgb_clf_pred)\n",
    "print('XGBoost Classifier:', xgb_clf_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation (SHAP)\n",
    "Interpret the best-performing classifier using SHAP to identify top features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_summary_plot(rf_clf, X_train_c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
